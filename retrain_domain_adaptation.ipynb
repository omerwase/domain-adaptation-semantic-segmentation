{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Domain Adaptation Network\n",
    "\n",
    "#### Setup notes: \n",
    "    1) Data file paths must be configured locally\n",
    "    1) CARALA train directory's expected structure: \n",
    "        - images in 'CameraRGB' directory \n",
    "        - labels in 'CameraSeg' directory\n",
    "    2) BDD test directory's expected structure:\n",
    "        - images in 'images' directory \n",
    "        - labels in 'labels' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import helper_functions_bdd as test_hf\n",
    "import helper_functions_carla as train_hf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "from functools import reduce\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Name and Paths\n",
    "#### Note: parameter values below must be re-assigned based on local directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'network_v7_da'\n",
    "MODEL_RESTORE_VER = '00'\n",
    "MODEL_SAVE_VER = '00_r0'\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'datasets', 'da')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train_carla')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test_bdd')\n",
    "RESTORE_DIR = os.path.join(os.getcwd(), 'saved_models', MODEL_NAME, MODEL_RESTORE_VER, 'score')\n",
    "SAVE_DIR = os.path.join(os.getcwd(), 'saved_models', MODEL_NAME, MODEL_SAVE_VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_fscore = 999.9   #TODO: change based on previous fscore\n",
    "best_loss = 0.0       #TODO: change based on previous loss\n",
    "\n",
    "EPOCHS = 200\n",
    "SHUFFLE_PER_EPOCH = True\n",
    "BATCH_SIZE = 12\n",
    "L2_REG = 1e-5\n",
    "STD_DEV = 1e-2\n",
    "LEARNING_RATE = 1e-5 # changed for next run\n",
    "MOMENTUM = 0.9\n",
    "KEEP_PROB = 0.5\n",
    "EPSILON = 1e-6\n",
    "ADAM_EPSILON = 1e-5\n",
    "SAVE_EPSILON = 1e-4\n",
    "\n",
    "TRAIN_TRIM = True\n",
    "TRAIN_TRIM_IND = (115, 523)\n",
    "TRAIN_RESHAPE = False\n",
    "TRAIN_NEW_SHAPE = (800, 408)  # shape after trim (without reshape)\n",
    "TRAIN_LABEL_CHANNELS = [10, 7, 2, 4, 5, 8, 9, 20, 30]\n",
    "\n",
    "TEST_TRIM = False\n",
    "TEST_TRIM_IND = (0, 720)     # original height\n",
    "TEST_RESHAPE = True\n",
    "TEST_NEW_SHAPE = (640, 360)\n",
    "TEST_LABEL_CHANNELS = [13, 0, 4, 11, 5, 1, 8, 20, 30]\n",
    "\n",
    "FLIP = True\n",
    "PREPROCESS = True\n",
    "NEW_LABELS = True\n",
    "CHANNEL_NAMES = ['Back', 'Vehi', 'Road', 'Fence', 'Ped', 'Poles', 'Side', 'Veg', 'BW', 'OT']\n",
    "LOSS_WEIGHTS = [0.6, 1.2, 0.6, 1.2, 1.2, 1.2, 0.7, 0.7, 0.7, 0.7]\n",
    "NUM_CLASSES = len(TRAIN_LABEL_CHANNELS) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'MODEL_NAME: {MODEL_NAME}')\n",
    "print(f'MODEL_RESTORE_VER: {MODEL_RESTORE_VER}')\n",
    "print(f'MODEL_SAVE_VER: {MODEL_SAVE_VER}')\n",
    "print(f'TRAIN_DIR: {TRAIN_DIR}')\n",
    "print(f'TEST_DIR: {TEST_DIR}')\n",
    "print(f'RESTORE_DIR: {RESTORE_DIR}')\n",
    "print(f'SAVE_DIR: {SAVE_DIR}')\n",
    "  \n",
    "print(f'SHUFFLE_PER_EPOCH: {SHUFFLE_PER_EPOCH}')\n",
    "print(f'BATCH_SIZE: {BATCH_SIZE}')\n",
    "print(f'L2_REG: {L2_REG}')\n",
    "print(f'STD_DEV: {STD_DEV}')\n",
    "print(f'LEARNING_RATE: {LEARNING_RATE}')\n",
    "print(f'MOMENTUM: {MOMENTUM}')\n",
    "print(f'KEEP_PROB: {KEEP_PROB}')\n",
    "print(f'EPSILON: {EPSILON}')\n",
    "print(f'ADAM_EPSILON: {ADAM_EPSILON}')\n",
    "    \n",
    "print(f'TRAIN_TRIM: {TRAIN_TRIM}')\n",
    "print(f'TRAIN_TRIM_IND: {TRAIN_TRIM_IND}')\n",
    "print(f'TRAIN_RESHAPE: {TRAIN_RESHAPE}')\n",
    "print(f'TRAIN_NEW_SHAPE: {TRAIN_NEW_SHAPE}')\n",
    "print(f'TRAIN_LABEL_CHANNELS: {TRAIN_LABEL_CHANNELS}')\n",
    "\n",
    "print(f'TEST_TRIM: {TEST_TRIM}')\n",
    "print(f'TEST_TRIM_IND: {TEST_TRIM_IND}')\n",
    "print(f'TEST_RESHAPE: {TEST_RESHAPE}')\n",
    "print(f'TEST_NEW_SHAPE: {TEST_NEW_SHAPE}')\n",
    "print(f'TEST_LABEL_CHANNELS: {TEST_LABEL_CHANNELS}')\n",
    "\n",
    "print(f'FLIP: {FLIP}')\n",
    "print(f'PREPROCESS: {PREPROCESS}')\n",
    "print(f'NEW_LABELS: {NEW_LABELS}')\n",
    "print(f'CHANNEL_NAMES: {CHANNEL_NAMES}')\n",
    "print(f'LOSS_WEIGHTS: {LOSS_WEIGHTS}')\n",
    "\n",
    "get_train_batch = train_hf.train_batch_gen(TRAIN_DIR, TRAIN_LABEL_CHANNELS,\n",
    "                                           preprocess=PREPROCESS, \n",
    "                                           new_labels=NEW_LABELS, \n",
    "                                           reshape=TRAIN_RESHAPE, \n",
    "                                           new_shape=TRAIN_NEW_SHAPE, \n",
    "                                           trim=TRAIN_TRIM, \n",
    "                                           trim_ind=TRAIN_TRIM_IND)\n",
    "\n",
    "get_test_batch, revert_trim_reshape = test_hf.test_batch_gen(TEST_DIR, TEST_LABEL_CHANNELS, \n",
    "                                                             preprocess=PREPROCESS, \n",
    "                                                             new_labels=NEW_LABELS,\n",
    "                                                             reshape=TEST_RESHAPE, \n",
    "                                                             new_shape=TEST_NEW_SHAPE, \n",
    "                                                             trim=TEST_TRIM,\n",
    "                                                             trim_ind=TEST_TRIM_IND)\n",
    "\n",
    "data_load_start = time.time()\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for images, labels, _ in get_test_batch(100):\n",
    "    test_images.append(images)\n",
    "    test_labels.append(labels)\n",
    "    \n",
    "test_images = np.array(test_images, dtype=np.uint8)\n",
    "test_images = test_images.reshape(-1, *test_images.shape[2:])\n",
    "test_labels = np.array(test_labels, dtype=np.uint8)\n",
    "test_labels = test_labels.reshape(-1, *test_labels.shape[2:])\n",
    "print(f'test_images.shape: {test_images.shape}')\n",
    "print(f'test_labels.shape: {test_labels.shape}')\n",
    "\n",
    "print(f'Data load time: {time.time() - data_load_start:#0.1f}s')\n",
    "\n",
    "flat_labels_size = reduce(lambda x, y: x*y, test_labels.shape[:-1])\n",
    "image_org_shape = (test_labels.shape[1], test_labels.shape[2])\n",
    "flat_offset = BATCH_SIZE*image_org_shape[0]*image_org_shape[1]\n",
    "\n",
    "saver = tf.train.import_meta_graph(os.path.join(RESTORE_DIR, MODEL_NAME + '.ckpt.meta'))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(RESTORE_DIR))\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    image_input = graph.get_tensor_by_name('image_input:0')\n",
    "    label_input = graph.get_tensor_by_name('label_input:0')\n",
    "    loss_weights = graph.get_tensor_by_name('loss_weights:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    l_rate = graph.get_tensor_by_name('l_rate:0')\n",
    "    adam_eps = graph.get_tensor_by_name('adam_eps:0')\n",
    "    prediction = graph.get_tensor_by_name('output/prediction:0')\n",
    "    total_loss = graph.get_tensor_by_name('optimize/total_loss:0')\n",
    "    opt = graph.get_operation_by_name('optimize/Adam')\n",
    "    \n",
    "    fscore_avg = 0.0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        print(f'\\nTraining epoch: {epoch+1}/{EPOCHS}')\n",
    "        \n",
    "        \n",
    "        for train_image_batch, train_label_batch, _ in get_train_batch(BATCH_SIZE):\n",
    "            \n",
    "            if FLIP:\n",
    "                if random.randint(0, 1) == 0:\n",
    "                    # horizontal flip\n",
    "                    train_image_batch = np.flip(train_image_batch, axis=2)\n",
    "                    train_label_batch = np.flip(train_label_batch, axis=2)\n",
    "                \n",
    "            _, loss = sess.run([opt, total_loss],\n",
    "                               feed_dict = {image_input: train_image_batch,\n",
    "                                            label_input: train_label_batch,\n",
    "                                            loss_weights: LOSS_WEIGHTS,\n",
    "                                            keep_prob: KEEP_PROB,\n",
    "                                            l_rate: LEARNING_RATE,\n",
    "                                            adam_eps: ADAM_EPSILON})\n",
    "        print(f'Training time: {(time.time() - start_time):#0.1f}s, loss: {loss:#0.5f}') \n",
    "        \n",
    "        sess_time = 0\n",
    "        total_preds = np.empty((flat_labels_size,), dtype=np.uint8)\n",
    "        total_labels = np.empty((flat_labels_size,), dtype=np.uint8)\n",
    "        for offset in range(0, len(test_images), BATCH_SIZE):\n",
    "            pred_time = time.time()\n",
    "            test_image_batch = test_images[offset:offset+BATCH_SIZE]\n",
    "            test_label_batch = test_labels[offset:offset+BATCH_SIZE]            \n",
    "            preds = sess.run(prediction, feed_dict = {image_input: test_image_batch,\n",
    "                                                     keep_prob: 1.0})\n",
    "            \n",
    "            preds = revert_trim_reshape(preds)\n",
    "            sess_time += time.time() - pred_time\n",
    "            \n",
    "            preds_result = np.array(preds, dtype=np.uint8).reshape(-1)\n",
    "            labels_result = test_label_batch.argmax(axis=3).reshape(-1)\n",
    "            \n",
    "            batch_offset = len(test_label_batch)*image_org_shape[0]*image_org_shape[1]\n",
    "            i = int(offset/BATCH_SIZE)\n",
    "            total_preds[i*flat_offset:i*flat_offset+batch_offset] = preds_result\n",
    "            total_labels[i*flat_offset:i*flat_offset+batch_offset] = labels_result\n",
    "            \n",
    "        print(f'Prediction session time: {sess_time:#0.1f}s')\n",
    "        eval_start_time = time.time()\n",
    "        metrics = precision_recall_fscore_support(total_labels, total_preds)\n",
    "        print(f'Evaluation time: {(time.time() - eval_start_time):#0.3f}s')\n",
    "        del total_preds\n",
    "        del total_labels \n",
    "        \n",
    "        str_title     = f'             '\n",
    "        str_recall    = f'Recall:    '\n",
    "        str_precision = f'Precision: '\n",
    "        str_f1        = f'F1 score:  '\n",
    "        str_support   = f'Support:   '\n",
    "        for i, val in enumerate(metrics[0]):\n",
    "            str_title += f'{CHANNEL_NAMES[i]:10}'\n",
    "            str_recall += f'{val:#10.4f}'\n",
    "            str_precision += f'{metrics[1][i]:#10.4f}'\n",
    "            str_f1 += f'{metrics[2][i]:#10.4f}'\n",
    "            str_support += f'{metrics[3][i]:10}'\n",
    "        print(str_title)\n",
    "        print(str_recall)\n",
    "        print(str_precision)\n",
    "        print(str_f1)\n",
    "        print(str_support)\n",
    "        \n",
    "        fscore_avg = np.mean(np.array(metrics[2]))\n",
    "        print(f'fscore_avg: {fscore_avg:#0.5f}')\n",
    "        print(f'Total time: {time.time()-start_time:#0.1f}s')\n",
    "        \n",
    "        if fscore_avg - best_fscore > SAVE_EPSILON:\n",
    "            best_fscore = fscore_avg\n",
    "            saver.save(sess, os.path.join(SAVE_DIR, 'score', MODEL_NAME + '.ckpt'))  \n",
    "            print('*************** MODEL SAVED ON SCORE ***************')\n",
    "        elif best_loss - loss > SAVE_EPSILON:\n",
    "            best_loss = loss\n",
    "            saver.save(sess, os.path.join(SAVE_DIR, 'loss', MODEL_NAME + '.ckpt'))  \n",
    "            print('******* model saved on loss *******')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
